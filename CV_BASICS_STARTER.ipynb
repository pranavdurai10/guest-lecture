{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbfbe9b3-4a75-4400-9f95-15c1940f90eb",
   "metadata": {},
   "source": [
    "# OpenCV Basics - Pranav Durai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b0ab4e-c175-431d-869e-a77166592082",
   "metadata": {},
   "source": [
    "### Reading, Displaying, Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c619fa-bcd0-4cb8-a638-730957492bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf3bcd5-eb23-4135-8043-e570bbf9ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image from directory - 1 for color, 0 for grayscale\n",
    "image = cv2.imread('assets/edge.png', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a92ad-64e5-4b98-b60b-3f3bb1d07f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image\n",
    "cv2.imshow('color_image', image)\n",
    "# Waits for a keystroke and Destroys all the windows created\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae110f8-656f-46a3-8da8-d9ba6e5aadf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write image with custom name\n",
    "cv2.imwrite('your-name.jpg', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e9eba1-14ca-4ef8-aac9-7d46f0dda460",
   "metadata": {},
   "source": [
    "### Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc056cf-bded-44b0-a230-d7f31b08285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image = cv2.resize(image, (480, 360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8354f50-2e19-4a74-9b8e-61354f35e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image\n",
    "cv2.imshow('Resized_Image', resized_image)\n",
    "# Waits for a keystroke and Destroys all the windows created\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a273a4-ad54-4be7-bc67-0beb4e4b5e61",
   "metadata": {},
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f02d25-71c5-41b6-9331-cd1aec68a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the rotation angle (in degrees)\n",
    "angle = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d198c6-9550-4f72-888d-ae5a1f0a35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image center coordinates\n",
    "height, width = image.shape[:2]\n",
    "center = (width // 2, height // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983104e5-0158-4d7c-b10f-1da9cdd395d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the rotation matrix\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b7712-48c0-465c-9364-870c61b05f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the rotation to the image\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50744b-f20e-43cf-a542-f17309ade0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image\n",
    "cv2.imshow('Rotated_Image', rotated_image)\n",
    "# Waits for a keystroke and Destroys all the windows created\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e04ce-2a62-45af-a16a-930347a5d62d",
   "metadata": {},
   "source": [
    "### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce4297-26bc-4a09-ab05-1c49edd6efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the region of interest (ROI) coordinates (x, y, width, height)\n",
    "x, y, width, height = 500, 200, 800, 600  # Adjust these values based on your specific cropping needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784e017-6c8a-4367-ac8b-5cf1a978f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the image using numpy array slicing\n",
    "cropped_image = image[y:y+height, x:x+width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0dd2d0-983b-47d5-aa60-bb2318486ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original and cropped images\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Cropped Image', cropped_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46020f-0a1a-470f-a0e8-e1ee543ae8f9",
   "metadata": {},
   "source": [
    "### Color Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b52df1a-d125-4430-8700-181c7d3abba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(B, G, R) = cv2.split(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e5e01-8502-4328-9d6d-e7899aab2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image\n",
    "cv2.imshow('R', R)\n",
    "cv2.imshow('G', G)\n",
    "cv2.imshow('B', B)\n",
    "# Waits for a keystroke and Destroys all the windows created\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f31998-f338-492e-9946-59f446347d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize each channel in color\n",
    "zeros = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "cv2.imshow(\"Red\", cv2.merge([zeros, zeros, R]))\n",
    "cv2.imshow(\"Green\", cv2.merge([zeros, G, zeros]))\n",
    "cv2.imshow(\"Blue\", cv2.merge([B, zeros, zeros]))\n",
    "# Waits for a keystroke and Destroys all the windows created\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e679c-1aa7-454c-ba84-8e12b7b98111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSV, YCrCb, LAB\n",
    "image_LAB = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "image_HSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "image_YCRCB = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6b79d-090c-4623-8788-c684a009fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('LAB', image_LAB)\n",
    "cv2.imshow('HSV', image_HSV)\n",
    "cv2.imshow('YCRCB', image_YCRCB)\n",
    "# Waits for a keystroke and Destroys all the windows created\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a763ae-c707-41d1-9f57-6b2c2fd403ae",
   "metadata": {},
   "source": [
    "### Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7cc309-e557-4a6f-9fde-7c077bdcb6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(img_gray, 150, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4befa9-9c6b-4aad-a08f-952b3e6ec890",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('B/W', img_gray)\n",
    "cv2.imshow('THRESH', thresh)\n",
    "# Waits for a keystroke and Destroys all the windows created\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef25c3-2a47-4ecf-8788-6348cc821432",
   "metadata": {},
   "source": [
    "### Image Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c37114-56cb-4372-afe5-aee302387508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gaussian Blur\n",
    "blurred_image = cv2.GaussianBlur(image, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ebf7c-eb6a-44e3-a0a4-a626af2e4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Sobel filtering (gradient computation)\n",
    "sobel_x = cv2.Sobel(blurred_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobel_y = cv2.Sobel(blurred_image, cv2.CV_64F, 0, 1, ksize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338cc3a-6f7c-4752-a1eb-659d55b42923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the results of Sobel x and y\n",
    "sobel_combined = cv2.magnitude(sobel_x, sobel_y)\n",
    "# Convert gradient magnitude to 8-bit for display\n",
    "sobel_combined = np.uint8(sobel_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c73b295-cd1c-4ac2-9535-8fa1b2028f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Canny edge detection\n",
    "canny_edges = cv2.Canny(blurred_image, 50, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e05be4-a8be-4ce6-a611-9dbd81bafd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original, blurred, Sobel-filtered, and Canny-edged images\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Gaussian Blur', blurred_image)\n",
    "cv2.imshow('Sobel Filtered', sobel_combined)\n",
    "cv2.imshow('Canny Edges', canny_edges)\n",
    "# Waits for a keystroke and Destroys all the windows created\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e944c-96e3-4073-8e56-7725b69c576c",
   "metadata": {},
   "source": [
    "### Transformation: Affline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa80939-1c1b-4609-a9df-4402f6412d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three points to create an affine transformation\n",
    "pts1 = np.float32([[50, 50], [200, 50], [50, 200]])\n",
    "pts2 = np.float32([[10, 100], [200, 50], [100, 250]])\n",
    "\n",
    "# Calculate the affine transformation matrix\n",
    "affine_matrix = cv2.getAffineTransform(pts1, pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468c784-0130-4044-832f-d2848deca218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the affine transformation to the image\n",
    "affine_transformed_image = cv2.warpAffine(image, affine_matrix, (image.shape[1], image.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d73bd5-ee46-4677-9ed2-3d236189745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original and transformed images\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Affine Transformed Image', affine_transformed_image)\n",
    "# Waits for a keystroke and Destroys all the windows created\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4054eb8f-5b5e-40af-833c-c5ae5f599c8b",
   "metadata": {},
   "source": [
    "### Transformation: Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a53acc-0115-4716-afe1-0d3a979342d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define four points to create a perspective transformation\n",
    "pts1 = np.float32([[56, 65], [368, 52], [28, 387], [389, 390]])\n",
    "pts2 = np.float32([[0, 0], [300, 0], [0, 300], [300, 300]])\n",
    "\n",
    "# Calculate the perspective transformation matrix\n",
    "perspective_matrix = cv2.getPerspectiveTransform(pts1, pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b99960-34b0-4155-b2a8-6a2bc5a22dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the perspective transformation to the image\n",
    "perspective_transformed_image = cv2.warpPerspective(image, perspective_matrix, (image.shape[1], image.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebea7137-122c-4bee-8705-96b1a8b71e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original and transformed images\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Perspective Transformed Image', perspective_transformed_image)\n",
    "# Waits for a keystroke and Destroys all the windows created\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c2c3d7-0a72-4eb7-9117-0d76f9bb509b",
   "metadata": {},
   "source": [
    "### Contours - use ferrari.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c835bdc7-c5b6-407f-b902-92fd36bf573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply thresholding to create a binary image\n",
    "_, binary_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45706e13-b063-476f-a937-ed98841f3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours in the binary image\n",
    "contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw contours on the original image\n",
    "contour_image = image.copy()\n",
    "cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)  # -1 means draw all contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b25af5e-3ed7-4fa2-a7f2-7478a8430f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original image and the image with contours\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Image with Contours', contour_image)\n",
    "# Waits for a keystroke and Destroys all the windows created\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e93d5a-b79d-4006-94f7-841cc71e9462",
   "metadata": {},
   "source": [
    "### Object Detection - Classical Computer Vision - use edge.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc3660-25a5-4dca-8f9f-d5ae15e109f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur to the grayscale image\n",
    "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e554913-b0fd-451e-a6c5-39f46e4300f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Canny edge detection\n",
    "canny_edges = cv2.Canny(blurred_image, 50, 150)\n",
    "\n",
    "# Find contours in the binary image\n",
    "contours, _ = cv2.findContours(canny_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac881fa-e77d-4ff1-940a-4aff62734e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter contours based on area to find the largest contour (assuming it's the car)\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "largest_contour = contours[5]\n",
    "\n",
    "# Get the bounding box of the largest contour\n",
    "x, y, w, h = cv2.boundingRect(largest_contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e07ba6-d892-47b6-9f11-adc2b3732643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the bounding box on the original image\n",
    "image_with_bounding_box = image.copy()\n",
    "cv2.rectangle(image_with_bounding_box, (x, y), (x + w, y + h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c79bf-6c61-47b4-bbd5-a37f42d97313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original image and the image with the bounding box\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Image with Bounding Box', image_with_bounding_box)\n",
    "# Waits for a keystroke and Destroys all the windows created\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
